{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7442f394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from torchvision.transforms import ToTensor,v2,Grayscale\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b700740",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layer_1 = nn.Sequential(\n",
    "          nn.Conv2d(1, 16, 3, padding=0),\n",
    "          nn.ReLU(),\n",
    "          nn.MaxPool2d(2))\n",
    "        self.conv_layer_2 = nn.Sequential(\n",
    "          nn.Conv2d(16, 32, 3, padding=0),\n",
    "          nn.ReLU(),\n",
    "          nn.MaxPool2d(2),\n",
    "          nn.Dropout(0.2))\n",
    "        self.classifier = nn.Sequential(\n",
    "          nn.Flatten(),\n",
    "          nn.Linear(in_features=32*30*30, out_features=128),\n",
    "          nn.ReLU(),\n",
    "          nn.Dropout(0.05),\n",
    "          nn.Linear(in_features=128, out_features=6))\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.conv_layer_1(x)\n",
    "        x = self.conv_layer_2(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fe7160a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 126, 126]             160\n",
      "              ReLU-2         [-1, 16, 126, 126]               0\n",
      "         MaxPool2d-3           [-1, 16, 63, 63]               0\n",
      "            Conv2d-4           [-1, 32, 61, 61]           4,640\n",
      "              ReLU-5           [-1, 32, 61, 61]               0\n",
      "         MaxPool2d-6           [-1, 32, 30, 30]               0\n",
      "           Dropout-7           [-1, 32, 30, 30]               0\n",
      "           Flatten-8                [-1, 28800]               0\n",
      "            Linear-9                  [-1, 128]       3,686,528\n",
      "             ReLU-10                  [-1, 128]               0\n",
      "          Dropout-11                  [-1, 128]               0\n",
      "           Linear-12                    [-1, 6]             774\n",
      "================================================================\n",
      "Total params: 3,692,102\n",
      "Trainable params: 3,692,102\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 6.84\n",
      "Params size (MB): 14.08\n",
      "Estimated Total Size (MB): 20.99\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ImageClassifier(\n",
       "  (conv_layer_1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_layer_2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=28800, out_features=128, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.05, inplace=False)\n",
       "    (4): Linear(in_features=128, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ImageClassifier()\n",
    "model.to('cuda')\n",
    "model.load_state_dict(torch.load(\"./weight/black095.pth\"))\n",
    "summary(model ,(1,128,128))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8849b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def totensor(result_image):\n",
    "    to_tensor = ToTensor()\n",
    "    tensor_image = to_tensor(result_image)\n",
    "    tensor_image = tensor_image.unsqueeze(0)\n",
    "    #tensor_image.shape\n",
    "    return tensor_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a422eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tensor_image):\n",
    "    out = model(tensor_image.to('cuda'))\n",
    "    soft=nn.Softmax(dim=1)\n",
    "    out = soft(out)\n",
    "    print(out)\n",
    "    max_value, max_index = torch.max(out, dim=1)\n",
    "\n",
    "    print(\"predict number\", max_index.item())\n",
    "    if max_index.item() == 1:\n",
    "        cv2.imshow(\"predict\",figure1)\n",
    "    elif max_index.item() == 2:\n",
    "        cv2.imshow(\"predict\",figure2)\n",
    "    elif max_index.item() == 3:\n",
    "        cv2.imshow(\"predict\",figure3)\n",
    "    elif max_index.item() == 4:\n",
    "        cv2.imshow(\"predict\",figure4)\n",
    "    elif max_index.item() == 5:\n",
    "        cv2.imshow(\"predict\",figure5)\n",
    "    elif max_index.item() == 0:\n",
    "        cv2.imshow(\"predict\",figure0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f76b730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "figure0 =cv2.imread('./RightLeft/0/zero1.jpg')\n",
    "figure1 =cv2.imread('./RightLeft/1/one1.jpg')\n",
    "figure2 =cv2.imread('./RightLeft/2/two1.jpg')\n",
    "figure3 =cv2.imread('./RightLeft/3/three1.jpg')\n",
    "figure4 =cv2.imread('./RightLeft/4/four1.jpg')\n",
    "figure5 =cv2.imread('./RightLeft/5/five1.jpg')\n",
    "cap = cv2.VideoCapture(0)\n",
    "i=1\n",
    "while 1:\n",
    "    _ , FrameImage = cap.read()\n",
    "    FrameImage = cv2.flip(FrameImage, 1)\n",
    "    cv2.imshow(\"Webcam\", FrameImage)\n",
    "    \n",
    "    hsi= cv2.cvtColor(FrameImage, cv2.COLOR_RGB2HSV)  #將圖片轉成HSI格式\n",
    "    h, s, i = cv2.split(hsi)        #將圖片拆成分別為HSI的單通道圖片\n",
    "    \n",
    "    saturation_threshold = 70  # 調整需要的閾值\n",
    "\n",
    "    # Saturation Slicing\n",
    "    saturation_mask = s < saturation_threshold\n",
    "    saturation_mask = saturation_mask.astype(np.uint8)\n",
    "\n",
    "    saturation_mask = 1- saturation_mask \n",
    "    saturation_mask = saturation_mask * 255  \n",
    "    result_image = cv2.resize(saturation_mask,(128,128),interpolation=cv2.INTER_AREA)\n",
    "    tensor_image = totensor(result_image)\n",
    "    cv2.imshow(\"mask\",saturation_mask)\n",
    "    print(tensor_image.shape)\n",
    "    break\n",
    "    predict(tensor_image)\n",
    "    \n",
    "    \n",
    "    interrupt = cv2.waitKey(10)\n",
    "    if interrupt & 0xFF == ord('q'):\n",
    "        break\n",
    "    elif interrupt & 0xFF == ord('s'):\n",
    "        path = './data/0/zero('+str(i)+').jpg'\n",
    "        cv2.imwrite(path,FrameImage)\n",
    "        i+=1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "286b91cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 128, 128])\n",
      "tensor([[1.0000e+00, 1.6077e-07, 1.1310e-08, 5.3467e-10, 6.1901e-10, 1.0443e-06]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "predict number 0\n"
     ]
    }
   ],
   "source": [
    "figure0 =cv2.imread('./BLACK/0/zero1.jpg')\n",
    "figure1 =cv2.imread('./BLACK/1/one1.jpg')\n",
    "figure2 =cv2.imread('./BLACK/2/two1.jpg')\n",
    "figure3 =cv2.imread('./BLACK/3/three1.jpg')\n",
    "figure4 =cv2.imread('./BLACK/4/four1.jpg')\n",
    "figure5 =cv2.imread('./BLACK/5/five1.jpg')\n",
    "from PIL import Image\n",
    "\n",
    "img= cv2.cvtColor(figure0, cv2.COLOR_BGR2GRAY)  #將圖片轉成HSI格式\n",
    "result_image = cv2.resize(img,(128,128),interpolation=cv2.INTER_AREA)\n",
    "\n",
    "to_tensor = ToTensor()\n",
    "tensor_image = to_tensor(result_image)\n",
    "tensor_image = tensor_image.unsqueeze(1)\n",
    "print(tensor_image.shape)\n",
    "predict(tensor_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ca0ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
